{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "234b1f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in c:\\users\\swapn\\anaconda3\\lib\\site-packages (0.20.9)\n",
      "Requirement already satisfied: Levenshtein==0.20.9 in c:\\users\\swapn\\anaconda3\\lib\\site-packages (from python-Levenshtein) (0.20.9)\n",
      "Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in c:\\users\\swapn\\anaconda3\\lib\\site-packages (from Levenshtein==0.20.9->python-Levenshtein) (2.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df897a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Levenshtein import distance\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "925890e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a1efaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Label</th>\n",
       "      <th>file</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>fo_o_fw_\"_by_bc</td>\n",
       "      <td>2228.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>All right, uh,</td>\n",
       "      <td>b</td>\n",
       "      <td>2228.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>feelings on what caused the S and L crisis</td>\n",
       "      <td>sd</td>\n",
       "      <td>2228.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>I guess I don't have a real technical knowledg...</td>\n",
       "      <td>sd</td>\n",
       "      <td>2228.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>I gather that there where large numbers of sit...</td>\n",
       "      <td>sd</td>\n",
       "      <td>2228.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Channel                                          Utterance            Label  \\\n",
       "0       A                                              Okay.  fo_o_fw_\"_by_bc   \n",
       "1       B                                     All right, uh,                b   \n",
       "2       B         feelings on what caused the S and L crisis               sd   \n",
       "3       B  I guess I don't have a real technical knowledg...               sd   \n",
       "4       B  I gather that there where large numbers of sit...               sd   \n",
       "\n",
       "       file start end  \n",
       "0  2228.txt            \n",
       "1  2228.txt            \n",
       "2  2228.txt            \n",
       "3  2228.txt            \n",
       "4  2228.txt            "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('text_data_nathan.csv')\n",
    "data['start'] = ''\n",
    "data['end'] = ''\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1e27181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process text-data-nathan before alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3b01e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performing cleanup both the channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d6f173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Utterance'] = data['Utterance'].str.lower()\n",
    "data['Utterance'] = data['Utterance'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7affc2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Utterance'] = data['Utterance'].replace('[^\\w +]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef9a431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Utterance'] = data['Utterance'].replace('uhhuh', 'umhum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b97aaed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Label</th>\n",
       "      <th>file</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>okay</td>\n",
       "      <td>fo_o_fw_\"_by_bc</td>\n",
       "      <td>2228.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>all right uh</td>\n",
       "      <td>b</td>\n",
       "      <td>2228.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>feelings on what caused the s and l crisis</td>\n",
       "      <td>sd</td>\n",
       "      <td>2228.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>i guess i dont have a real technical knowledge...</td>\n",
       "      <td>sd</td>\n",
       "      <td>2228.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>i gather that there where large numbers of sit...</td>\n",
       "      <td>sd</td>\n",
       "      <td>2228.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199735</th>\n",
       "      <td>A</td>\n",
       "      <td>no</td>\n",
       "      <td>nn</td>\n",
       "      <td>3528.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199736</th>\n",
       "      <td>A</td>\n",
       "      <td>i dont</td>\n",
       "      <td>sd</td>\n",
       "      <td>3528.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199737</th>\n",
       "      <td>A</td>\n",
       "      <td>i dont either</td>\n",
       "      <td>sd</td>\n",
       "      <td>3528.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199738</th>\n",
       "      <td>B</td>\n",
       "      <td>but i i know thats certainly helped a lot in t...</td>\n",
       "      <td>sv</td>\n",
       "      <td>3528.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199739</th>\n",
       "      <td>A</td>\n",
       "      <td>yeah</td>\n",
       "      <td>b</td>\n",
       "      <td>3528.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199740 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Channel                                          Utterance  \\\n",
       "0            A                                               okay   \n",
       "1            B                                       all right uh   \n",
       "2            B         feelings on what caused the s and l crisis   \n",
       "3            B  i guess i dont have a real technical knowledge...   \n",
       "4            B  i gather that there where large numbers of sit...   \n",
       "...        ...                                                ...   \n",
       "199735       A                                                 no   \n",
       "199736       A                                             i dont   \n",
       "199737       A                                      i dont either   \n",
       "199738       B  but i i know thats certainly helped a lot in t...   \n",
       "199739       A                                               yeah   \n",
       "\n",
       "                  Label      file start end  \n",
       "0       fo_o_fw_\"_by_bc  2228.txt            \n",
       "1                     b  2228.txt            \n",
       "2                    sd  2228.txt            \n",
       "3                    sd  2228.txt            \n",
       "4                    sd  2228.txt            \n",
       "...                 ...       ...   ...  ..  \n",
       "199735               nn  3528.txt            \n",
       "199736               sd  3528.txt            \n",
       "199737               sd  3528.txt            \n",
       "199738               sv  3528.txt            \n",
       "199739                b  3528.txt            \n",
       "\n",
       "[199740 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "add01b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Label</th>\n",
       "      <th>file</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>okay</td>\n",
       "      <td>fo_o_fw_\"_by_bc</td>\n",
       "      <td>2228.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>all right uh</td>\n",
       "      <td>b</td>\n",
       "      <td>2228.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>feelings on what caused the s and l crisis</td>\n",
       "      <td>sd</td>\n",
       "      <td>2228.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>i guess i dont have a real technical knowledge...</td>\n",
       "      <td>sd</td>\n",
       "      <td>2228.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>i gather that there where large numbers of sit...</td>\n",
       "      <td>sd</td>\n",
       "      <td>2228.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Channel                                          Utterance            Label  \\\n",
       "0       A                                               okay  fo_o_fw_\"_by_bc   \n",
       "1       B                                       all right uh                b   \n",
       "2       B         feelings on what caused the s and l crisis               sd   \n",
       "3       B  i guess i dont have a real technical knowledge...               sd   \n",
       "4       B  i gather that there where large numbers of sit...               sd   \n",
       "\n",
       "       file start end  \n",
       "0  2228.txt            \n",
       "1  2228.txt            \n",
       "2  2228.txt            \n",
       "3  2228.txt            \n",
       "4  2228.txt            "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a87a1812",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to cleanup individual transcription files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "367fb1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcripts(df):\n",
    "    df = df[df['text'] != '[noise]']\n",
    "    df = df[df['text'] != '[silence]']\n",
    "    df = df[df['text'] != '[laughter]']\n",
    "    df = df[df['text'] != '[vocalized-noise]']\n",
    "    df['text'] = df['text'].str.lower()\n",
    "    df['text'] = df['text'].replace('[^\\w +]', '', regex=True)\n",
    "    df['text'] = df['text'].str.strip()\n",
    "    df = df[df['text'] != 'umhum']\n",
    "#     data['Utterance'] = data['Utterance'].replace('uhhuh', 'umhum')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "958a8bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcripts_lines(lines, sep=' '):\n",
    "    cleaned = []\n",
    "    for line in lines:\n",
    "        try:\n",
    "            splits = [x.strip() for x in line.split(' ') if len(x) != 0]\n",
    "            if splits[3] == '[noise]' or splits[3] == \"[silence]\" or splits[3] == '[laughter]' or splits[3] == '[vocalized-noise]' or splits[3] == 'um-hum':\n",
    "                continue\n",
    "        except IndexError:\n",
    "            splits = [x.strip() for x in line.split('\\t') if len(x) != 0]\n",
    "            if splits[3] == '[noise]' or splits[3] == \"[silence]\" or splits[3] == '[laughter]' or splits[3] == '[vocalized-noise]' or splits[3] == 'um-hum':\n",
    "                continue\n",
    "        splits[3] = re.sub('[^\\w +]', '', splits[3].lower())\n",
    "        if len(splits) > 4:\n",
    "            print(f'Data from word level transcript file has garbage cols. Reading first 4...')\n",
    "            cleaned.append(splits[:4])\n",
    "        else:\n",
    "            cleaned.append(splits)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eacbc9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Performing time alignments, after cleaning data in individual transcript files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8290f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "switchboard_data_folder_path = 'Switchboard/swb_ms98_transcriptions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2325cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aim is to read word timings (word -level) and add start and end times to 'data' dataframe\n",
    "# Doing this for channel 'A'\n",
    "prev_file = None\n",
    "prev_file_index = 0\n",
    "processed_files = set()\n",
    "for index, row in data[data['Channel'] == 'A'].iterrows():\n",
    "    processed_files.add(row['file'])\n",
    "    if not row['file'] == '3158.txt':\n",
    "        continue\n",
    "    if row['file'] == '3136.txt':\n",
    "        continue\n",
    "        \n",
    "    if row['Utterance'] == 'umhum': continue\n",
    "    folder_id = row['file'][:2]\n",
    "    if prev_file != row['file']:\n",
    "        prev_file = row['file']\n",
    "        prev_file_index = 0\n",
    "    \n",
    "    # Processing for channel A\n",
    "    transcript_file = f\"{switchboard_data_folder_path}{folder_id}/{row['file'][:-4]}/sw{row['file'][:-4]}A-ms98-a-word.text\"\n",
    "\n",
    "    word_timings = open(transcript_file, mode='r')\n",
    "    word_timings = word_timings.readlines()\n",
    "    if row['file'] in ('3646.txt', '2776.txt', '3751.txt', '4628.txt', '2927.txt', '3187.txt'):\n",
    "        word_timings = clean_transcripts_lines(word_timings, sep='\\t')\n",
    "    else:\n",
    "        word_timings = clean_transcripts_lines(word_timings)\n",
    "    word_timings = pd.DataFrame(word_timings, columns=['_', 'start', 'end', 'text'])\n",
    "    word_timings_index = 0\n",
    "    \n",
    "    try:\n",
    "        if ' ' not in row['Utterance'].strip():\n",
    "            if distance(row['Utterance'].strip(), word_timings.iloc[prev_file_index]['text']) == 0:\n",
    "                #print(f'Found the utterance in word-level transcript file, adding start and end timings')\n",
    "                data.iloc[index]['start'] = word_timings.iloc[prev_file_index]['start']\n",
    "                data.iloc[index]['end'] = word_timings.iloc[prev_file_index]['end']\n",
    "                prev_file_index += 1\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            uttr_splits = row['Utterance'].split(' ')\n",
    "            first_uttr_word, last_uttr_word = uttr_splits[0], uttr_splits[-1]\n",
    "            count_last_uttr = row['Utterance'].count(last_uttr_word)\n",
    "            count_last_uttr = Counter(uttr_splits).get(last_uttr_word)\n",
    "            if not distance(word_timings.iloc[prev_file_index]['text'], first_uttr_word) <= 4 or len(first_uttr_word) <= distance(word_timings.iloc[prev_file_index]['text'], first_uttr_word):\n",
    "                continue\n",
    "            temp = None\n",
    "            while count_last_uttr != 0:\n",
    "                if not temp:\n",
    "                    temp = prev_file_index\n",
    "                if prev_file_index - temp >= len(uttr_splits):\n",
    "                    # Mainly to check for words such as loans and loan, but just for last words\n",
    "                    if distance(word_timings.iloc[prev_file_index]['text'], last_uttr_word) <= 1:\n",
    "                        prev_file_index += 1\n",
    "                        count_last_uttr -= 1\n",
    "                    else:\n",
    "                        prev_file_index += 1\n",
    "                elif distance(word_timings.iloc[prev_file_index]['text'], last_uttr_word) == 0:\n",
    "                    prev_file_index += 1\n",
    "                    count_last_uttr -= 1\n",
    "                else:\n",
    "                    prev_file_index += 1\n",
    "\n",
    "                if count_last_uttr == 0:\n",
    "                    data.iloc[index]['start'] = word_timings.iloc[temp]['start']\n",
    "                    data.iloc[index]['end'] = word_timings.iloc[prev_file_index - 1]['end']\n",
    "                    break\n",
    "    except IndexError:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f40709e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n",
      "Data from word level transcript file has garbage cols. Reading first 4...\n"
     ]
    }
   ],
   "source": [
    "# Aim is to read word timings (word -level) and add start and end times to 'data' dataframe\n",
    "# Doing this for channel 'B'\n",
    "prev_file = None\n",
    "prev_file_index = 0\n",
    "processed_files = set()\n",
    "for index, row in data[data['Channel'] == 'B'].iterrows():\n",
    "    processed_files.add(row['file'])\n",
    "    if row['file'] == '3136.txt':\n",
    "        continue\n",
    "        \n",
    "    if row['Utterance'] == 'umhum': continue\n",
    "#     print(f'Starting for row --> \\n{row}')\n",
    "    folder_id = row['file'][:2]\n",
    "    if prev_file != row['file']:\n",
    "        prev_file = row['file']\n",
    "        prev_file_index = 0\n",
    "    \n",
    "    # Processing for channel A\n",
    "    transcript_file = f\"{switchboard_data_folder_path}{folder_id}/{row['file'][:-4]}/sw{row['file'][:-4]}B-ms98-a-word.text\"\n",
    "\n",
    "    word_timings = open(transcript_file, mode='r')\n",
    "    word_timings = word_timings.readlines()\n",
    "#     if '3646.txt' == row['file'] or '2776.txt' == row['file'] or '3751.txt' == row['file'] or '4628.txt' == row['file']:\n",
    "    word_timings = clean_transcripts_lines(word_timings)\n",
    "    word_timings = pd.DataFrame(word_timings, columns=['_', 'start', 'end', 'text'])\n",
    "    word_timings_index = 0\n",
    "\n",
    "    try:\n",
    "        if ' ' not in row['Utterance'].strip():\n",
    "            if distance(row['Utterance'].strip(), word_timings.iloc[prev_file_index]['text']) == 0:\n",
    "                data.iloc[index]['start'] = word_timings.iloc[prev_file_index]['start']\n",
    "                data.iloc[index]['end'] = word_timings.iloc[prev_file_index]['end']\n",
    "                prev_file_index += 1\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            uttr_splits = row['Utterance'].split(' ')\n",
    "            first_uttr_word, last_uttr_word = uttr_splits[0], uttr_splits[-1]\n",
    "\n",
    "            count_last_uttr = row['Utterance'].count(last_uttr_word)\n",
    "            count_last_uttr = Counter(uttr_splits).get(last_uttr_word)\n",
    "            if not distance(word_timings.iloc[prev_file_index]['text'], first_uttr_word) <= 4 or len(first_uttr_word) <= distance(word_timings.iloc[prev_file_index]['text'], first_uttr_word):\n",
    "                continue\n",
    "            temp = None\n",
    "            while count_last_uttr != 0:\n",
    "                if not temp:\n",
    "                    temp = prev_file_index\n",
    "                if prev_file_index - temp >= len(uttr_splits):\n",
    "                    # Mainly to check for words such as loans and loan, but just for last words\n",
    "                    if distance(word_timings.iloc[prev_file_index]['text'], last_uttr_word) <= 1:\n",
    "                        prev_file_index += 1\n",
    "                        count_last_uttr -= 1\n",
    "                    else:\n",
    "                        prev_file_index += 1\n",
    "                elif distance(word_timings.iloc[prev_file_index]['text'], last_uttr_word) == 0:\n",
    "                    prev_file_index += 1\n",
    "                    count_last_uttr -= 1\n",
    "                else:\n",
    "                    prev_file_index += 1\n",
    "\n",
    "                if count_last_uttr == 0:\n",
    "                    data.iloc[index]['start'] = word_timings.iloc[temp]['start']\n",
    "                    data.iloc[index]['end'] = word_timings.iloc[prev_file_index - 1]['end']\n",
    "                    break\n",
    "    except IndexError:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffb65ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('text_data_nathan__with_timestamps.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63607936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dbf2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce29a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
